
# Eagle Dev ðŸ¦…

AplicaciÃ³n de diagnÃ³stico automÃ¡tico de enfermedades pulmonares usando aprendizaje profundo y procesamiento distribuido.

## ðŸ“ Repositorio

https://github.com/jhonmvr/eagle_dev

## ðŸ‘¨â€ðŸŽ“ Proyecto acadÃ©mico

- **Universidad Israel**
- **Carrera:** IngenierÃ­a en InformÃ¡tica
- **Curso:** Octavo semestre, Paralelo A
- **Estudiantes:**  
  - Romero Navarrete Jhon Valdemar  
  - Mosquera Sotomayor Jorge AndrÃ©s  
  - Chicaiza Manosalvas Gonzalo Daniel  

---

## ðŸ§  Modelo de ClasificaciÃ³n

Se utilizÃ³ **MobileNetV2** para la clasificaciÃ³n y segmentaciÃ³n de imÃ¡genes de rayos X de tÃ³rax. El modelo fue entrenado usando TensorFlow y evaluado con mÃ©tricas clave.


## ðŸ§© Â¿QuÃ© hace el cÃ³digo?

1. **Carga y preprocesamiento de datos:**
   - Lee metadatos desde archivos Excel y verifica rutas a imÃ¡genes y mÃ¡scaras.
   - Usa `Pillow` para cargar, redimensionar y convertir imÃ¡genes a arreglos `numpy`.

2. **GeneraciÃ³n eficiente de datos:**
   - `MultiTaskDataGenerator` carga imÃ¡genes en batches (no toda la RAM), ideal para equipos con recursos limitados.

3. **Modelo de Deep Learning:**
   - Basado en `MobileNetV2` (preentrenado con ImageNet).
   - Agrega dos salidas:
     - ClasificaciÃ³n: softmax de 3 clases.
     - SegmentaciÃ³n: mapa binario de mÃ¡scara con `sigmoid`.

4. **Entrenamiento distribuido:**
   - Compatible con `tf.distribute.MultiWorkerMirroredStrategy` para escalar en entornos con Hadoop.
   - Uso de HDFS como backend para datasets grandes.

5. **Registro y visualizaciÃ³n:**
   - Guarda logs de entrenamiento (`training_log.csv`).
   - Grafica precisiÃ³n y pÃ©rdidas (`.png`) al finalizar.

---

## ðŸ“¦ JustificaciÃ³n de librerÃ­as

| LibrerÃ­a              | Motivo de uso                                                                 |
|------------------------|------------------------------------------------------------------------------|
| `TensorFlow / Keras`  | Framework robusto, eficiente y compatible con CPU para entrenamiento profundo. |
| `MobileNetV2`         | Arquitectura ligera, eficiente en RAM y con precisiÃ³n adecuada (>85%).         |
| `Pillow`              | Para procesamiento ligero de imÃ¡genes sin sobrecargar RAM.                    |
| `NumPy`, `Pandas`     | Manejo eficiente de datos estructurados.                                       |
| `tf.keras.utils.Sequence` | Generador eficiente compatible con `fit()` que evita sobrecargar memoria.  |
| `matplotlib`          | Para graficar precisiÃ³n y pÃ©rdida por Ã©poca.                                  |
| `tf.io.gfile`         | Lectura desde HDFS para integrarse con Hadoop.                                |

---

## ðŸ§ª Respuestas al Caso de InnovaciÃ³n 2025

### ðŸ”¹ Â¿Por quÃ© se eligiÃ³ MobileNetV2?
- MobileNetV2 estÃ¡ optimizado para entornos sin GPU.
- En inferencia solo consume ~1GB RAM.
- Tiene precisiÃ³n > 90% en COVID en mÃºltiples benchmarks.

### ðŸ”¹ Â¿CÃ³mo cumple con los requisitos tÃ©cnicos?
| Requisito              | Cumplimiento                                                             |
|------------------------|---------------------------------------------------------------------------|
| RAM â‰¤ 12 GB            | Uso de generadores evita cargar imÃ¡genes completas a RAM.                |
| Sin GPU                | Entrenamiento e inferencia 100% en CPU.                                  |
| Tiempo â‰¤ 18h           | Entrena 3.6k imÃ¡genes en < 1h (en CPU), escalable con Hadoop.             |
| Almacenamiento â‰¤ 20GB  | Dataset original + aumentos no excede 2GB.                               |

### ðŸ”¹ Â¿Por quÃ© usar (o no) Hadoop?

- âœ… **SÃ­ se usa Hadoop**: cuando el dataset crece (50k+ imÃ¡genes), HDFS permite distribuir los datos, y TensorFlow distribuido entrena en paralelo con `MultiWorkerMirroredStrategy`.

- âŒ **No es obligatorio**: si solo se procesan imÃ¡genes en lotes pequeÃ±os, Dask o tf.data serÃ­an suficientes. Se justifica en nuestro caso por escalabilidad futura y como ejercicio de innovaciÃ³n.

### ðŸ”¹ Alternativas de mejora e innovaciÃ³n:
- Uso de `.keras` en lugar de `.h5` (formato moderno, mÃ¡s eficiente).
- Guardado automÃ¡tico de logs y grÃ¡ficas de mÃ©tricas.
- Compatible con despliegue en app de escritorio (Tkinter + TensorFlow Lite si se requiere).

---

## ðŸ“Š Resultados esperados

- Accuracy de clasificaciÃ³n en validaciÃ³n: ~92.9%
- PÃ©rdida combinada total (clasificaciÃ³n + segmentaciÃ³n): ~0.32
- Uso de RAM durante entrenamiento: entre 3â€“6â€¯GB.
- Tiempo total estimado en CPU: ~2.5 horas para 3,600 imÃ¡genes.

---

## ðŸ–¥ï¸ Requisitos para ejecuciÃ³n

- Python 3.8+
- TensorFlow 2.11+
- Pandas, Pillow, Matplotlib

InstalaciÃ³n:

```bash
pip install -r ./requirements.txt
```



### ðŸ“ˆ PrecisiÃ³n de ClasificaciÃ³n

![PrecisiÃ³n](./results/accuracy_plot.png)

- La precisiÃ³n de entrenamiento se incrementa desde **0.79** hasta cerca de **0.92**.
- La validaciÃ³n alcanza una precisiÃ³n estable alrededor de **0.93**, sin signos de sobreajuste.

### ðŸ“‰ PÃ©rdida total

![PÃ©rdida total](./results/loss_plot.png)

- La pÃ©rdida disminuye constantemente en entrenamiento y validaciÃ³n.
- La validaciÃ³n converge cerca de **0.33**, lo que refuerza un entrenamiento estable.

### ðŸŽ¯ PÃ©rdida de SegmentaciÃ³n

![PÃ©rdida de segmentaciÃ³n](./results/segmentation_loss_plot.png)

- La pÃ©rdida de segmentaciÃ³n decrece progresivamente.
- La diferencia entre entrenamiento y validaciÃ³n es baja â†’ el modelo generaliza correctamente.

### â±ï¸ Tiempo por Ã©poca

![Tiempo por Ã©poca](./results/epoch_time_plot.png)

- El tiempo por Ã©poca se mantiene entre **4.5** y **5 minutos**.

---

## ðŸ–¥ï¸ AnÃ¡lisis de Uso de Recursos

### ðŸ”§ CPU

![Uso de CPU](./results/cpu_usage.png)

- Uso promedio de CPU entre **85%â€“89%** durante el entrenamiento (sin GPU activa).

### ðŸ§  RAM

![Uso de RAM](./results/ram_usage.png)

- El uso oscilÃ³ entre **67% y 70.5%**, sin picos anormales.

### ðŸŽ® GPU

![Uso de GPU](./results/gpu_usage.png)

- Pico inicial en la Ã©poca 1 (~44%) pero luego cae a **casi 0%**, indicando que el entrenamiento principal fue en CPU.

### ðŸ“¦ Memoria de GPU

![Memoria de GPU](./results/gpu_memory_usage.png)

- Se mantuvo entre **45.5% y 48.5%** por reserva automÃ¡tica de memoria por TensorFlow u otros procesos.

---

## âš™ï¸ Eficiencia del Sistema

- Resultado ejemplo: **Normal**
- Confianza del modelo: **92.99%**
- Memoria RAM: **606 MB**
- CPU usada: **6.4%**
- AplicaciÃ³n desarrollada con **PyQt5**
- El modelo se carga localmente (`.keras`), sin necesidad de conexiÃ³n a internet.

---

## ðŸ˜ Entrenamiento Distribuido (Hadoop + TensorFlow)

Se implementÃ³ un clÃºster **pseudo-distribuido Hadoop** con Docker usando la imagen oficial de [BDE2020](https://github.com/big-data-europe/docker-hadoop).

### ðŸ—‚ï¸ Flujo de trabajo

1. Montaje de datasets (`dataset.zip`) en HDFS:
   ```bash
   docker cp dataset.zip namenode:/dataset.zip
   hdfs dfs -mkdir -p /user/jhon/dataset
   hdfs dfs -put /dataset/* /user/jhon/dataset
   ```