import glob
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay

# === Leer todos los CSV generados por Spark ===
csv_files = glob.glob("predicciones.csv/part-*.csv")
df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)

# Normalizar nombres de columnas (opcional)
df.columns = [col.strip().capitalize() for col in df.columns]

# === Precisi√≥n general ===
accuracy = accuracy_score(df["Actual"], df["Predicted"])
print(f"\n‚úÖ Precisi√≥n total: {accuracy * 100:.2f}%")

# === Tabla de conteo por clase ===
conteo = df.groupby(["Actual", "Predicted"]).size().unstack(fill_value=0)
print("\nüìä Conteo por clase (tabla de clasificaci√≥n):")
print(conteo)

# === Matriz de confusi√≥n ===
labels = sorted(df["Actual"].unique())
cm = confusion_matrix(df["Actual"], df["Predicted"], labels=labels)

# === Mostrar y guardar matriz de confusi√≥n ===
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap=plt.cm.Blues)
plt.title("Matriz de Confusi√≥n")
plt.savefig("matriz_confusion.png")
plt.show()

# === Precisi√≥n por clase (recall) ===
aciertos_por_clase = conteo.lookup(labels, labels)
total_por_clase = conteo.sum(axis=1).values
precision_por_clase = (aciertos_por_clase / total_por_clase) * 100

# === Gr√°fico de precisi√≥n por clase ===
plt.figure()
plt.bar(labels, precision_por_clase)
plt.ylabel("Precisi√≥n (%)")
plt.title("Precisi√≥n por clase")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("precision_por_clase.png")
plt.show()
