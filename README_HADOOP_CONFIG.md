
# Proyecto: Clasificaci√≥n y Segmentaci√≥n Pulmonar con MobileNetV2

## ‚öôÔ∏è Configuraci√≥n del entorno y ejecuci√≥n distribuida

### üìÅ Archivo `.env`

Guarda este archivo en la ra√≠z del proyecto:

```env
# Configuraciones del modelo y entrenamiento
IMG_SIZE=224
BATCH_SIZE=8
EPOCHS=10
CLASSES=COVID,Normal,Viral_Pneumonia

# Ruta del dataset en HDFS
DATASET_ROOT=hdfs:///user/jhon/dataset

# Archivos de salida
MODEL_PATH=covid_multitask_model.keras
TRAINING_LOG=training_log.csv
```

> ‚úÖ Usa [`python-dotenv`](https://pypi.org/project/python-dotenv/) para cargar autom√°ticamente estas variables en el script de entrenamiento.

---

### üöÄ Acceso a la Interfaz Gr√°fica de Hadoop (NameNode)

Con tu configuraci√≥n Docker, puedes acceder a la interfaz gr√°fica de HDFS en:

```
http://localhost:9870
```

Desde all√≠ puedes explorar los archivos del HDFS:
- Utiliza **‚ÄúUtilities > Browse the file system‚Äù**
- O entra directo: `http://localhost:9870/explorer.html#/user/jhon/dataset`

---

### üß† Entrenamiento distribuido (opcional)

Para ejecutar el entrenamiento de forma paralela en m√∫ltiples nodos con `MultiWorkerMirroredStrategy`, necesitas definir la variable `TF_CONFIG` en cada nodo. Ejemplo para 2 workers:

#### üñ•Ô∏è Nodo 0:

```bash
export TF_CONFIG='{
  "cluster": {
    "worker": ["localhost:12345", "localhost:12346"]
  },
  "task": {
    "type": "worker",
    "index": 0
  }
}'
python train_with_hadoop.py
```

#### üñ•Ô∏è Nodo 1:

```bash
export TF_CONFIG='{
  "cluster": {
    "worker": ["localhost:12345", "localhost:12346"]
  },
  "task": {
    "type": "worker",
    "index": 1
  }
}'
python train_with_hadoop.py
```

Puedes reemplazar `"localhost"` por la IP real del contenedor o nodo en red.

---

### üê≥ Puertos definidos en Docker (`docker-compose.yml`)

Aseg√∫rate de tener expuestos estos puertos en tu archivo:

```yaml
namenode:
  ports:
    - "9870:9870"  # Web UI del NameNode
    - "9000:9000"  # RPC principal del HDFS
```

---

### üì¶ Dependencias requeridas

```bash
pip install tensorflow pandas pillow matplotlib python-dotenv
```

---

### üîé Consejos de ejecuci√≥n

- Verifica que los archivos `.metadata.xlsx`, im√°genes y m√°scaras est√©n correctamente subidos a HDFS.
- Usa `hdfs dfs -ls /user/jhon/dataset` para confirmar.
- El modelo y los logs se guardan autom√°ticamente con los nombres definidos en el `.env`.
- En producci√≥n o entrenamiento prolongado, aseg√∫rate de monitorear el uso de RAM y CPU.

---
