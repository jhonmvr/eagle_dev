
# Proyecto: Clasificaci√≥n y Segmentaci√≥n Pulmonar con MobileNetV2

## ‚öôÔ∏è Configuraci√≥n del entorno y ejecuci√≥n distribuida

### üìÅ Archivo `.env`

Guarda este archivo en la ra√≠z del proyecto:

```env
# Configuraciones del modelo y entrenamiento
IMG_SIZE=224
BATCH_SIZE=8
EPOCHS=10
CLASSES=COVID,Normal,Viral Pneumonia

# Ruta del dataset en HDFS
DATASET_ROOT=hdfs:///user/jhon/dataset

# Archivos de salida
MODEL_PATH=covid_multitask_model.keras
TRAINING_LOG=training_log.csv
```

> ‚úÖ Usa [`python-dotenv`](https://pypi.org/project/python-dotenv/) para cargar autom√°ticamente estas variables en el script de entrenamiento.

---

### üß† Entrenamiento distribuido (opcional)

Para ejecutar el entrenamiento de forma paralela en m√∫ltiples nodos con `MultiWorkerMirroredStrategy`, necesitas definir la variable `TF_CONFIG` en cada nodo. Ejemplo para 2 nodos locales:

#### üñ•Ô∏è Nodo 0:

```bash
export TF_CONFIG='{
  "cluster": {
    "worker": ["localhost:12345", "localhost:12346"]
  },
  "task": {
    "type": "worker",
    "index": 0
}'
python train_with_hadoop.py
```

#### üñ•Ô∏è Nodo 1:

```bash
export TF_CONFIG='{
  "cluster": {
    "worker": ["localhost:12345", "localhost:12346"]
  },
  "task": {
    "type": "worker",
    "index": 1
}'
python train_with_hadoop.py
```

Puedes adaptar `"localhost:12345"` a direcciones IP reales si est√°s en red.

---

### üì¶ Dependencias requeridas

```bash
pip install tensorflow pandas pillow matplotlib python-dotenv
```

---

### üîé Consejos de ejecuci√≥n

- Aseg√∫rate de que los archivos `.metadata.xlsx`, im√°genes y m√°scaras est√©n disponibles en el mismo HDFS que especificaste en `DATASET_ROOT`.
- Si no usas m√∫ltiples nodos, el entrenamiento funcionar√° en modo normal sin necesidad de definir `TF_CONFIG`.
- El modelo y los logs se guardan autom√°ticamente con los nombres definidos en el `.env`.

